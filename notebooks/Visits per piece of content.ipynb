{
 "metadata": {
  "name": "Visits per piece of content"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import dora as dr\n",
      "from pandas.io.ga import read_ga\n",
      "from pandas.io.parsers import read_table\n",
      "from datetime import datetime, date, timedelta\n",
      "from dora.auth import ga\n",
      "from dora import auth"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Retrieve total visits by date\n",
      "metrics = [\"visits\"]\n",
      "dimensions = [\"date\"]\n",
      "\n",
      "start_date = date(2012, 10, 1)\n",
      "end_date = date(2013, 1, 23)\n",
      "\n",
      "daily_visits = read_ga(metrics, dimensions=dimensions, start_date=start_date, end_date=end_date, secrets=ga.SECRETS, token_file_name=ga.TOKEN_FILE_NAME)\n",
      "daily_visits = daily_visits.reset_index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Retrieve visits by date and pagePathLevel1\n",
      "# will be in a variable called full_data\n",
      "full_data = None\n",
      "metrics = ['visits']\n",
      "dimensions = ['date', 'pagePathLevel1']\n",
      "\n",
      "start_date = date(2012, 10, 1)\n",
      "end_date = date.today()\n",
      "current_date = start_date\n",
      "\n",
      "while current_date < end_date:\n",
      "    date_string = current_date.strftime(\"%Y-%m-%d\")\n",
      "    data_section = read_ga(metrics, dimensions=dimensions, start_date=date_string, end_date=date_string, secrets=ga.SECRETS, token_file_name=ga.TOKEN_FILE_NAME)\n",
      "    \n",
      "    if full_data is None:\n",
      "        full_data = data_section\n",
      "    else:\n",
      "        full_data = pd.concat([full_data, data_section])\n",
      "    current_date += timedelta(days=1)\n",
      "full_data = full_data.reset_index().rename(columns={\"pagePathLevel1\":\"path\"})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add total daily visits to the full data set\n",
      "full_data = pd.merge(daily_visits, full_data, on=\"date\")\\\n",
      "    .rename(columns={\"visits_x\":\"total_visits\", \"visits_y\":\"visits\"})\\\n",
      "    .reindex(columns=[\"date\", \"path\", \"visits\", \"total_visits\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Clean up the path\n",
      "def strip_trailing_slash(path):\n",
      "    if len(path) == 1 or path[-1] != \"/\":\n",
      "        return path\n",
      "    else:\n",
      "        return path[:-1]\n",
      "\n",
      "def strip_query_string(path):\n",
      "    return path.split(\"?\")[0]\n",
      "\n",
      "full_data[\"path\"] = full_data[\"path\"].map(unicode.lower)\n",
      "full_data[\"path\"] = full_data[\"path\"].map(strip_trailing_slash)\n",
      "full_data[\"path\"] = full_data[\"path\"].map(strip_query_string)\n",
      "\n",
      "# Sum up visits by date and path (because we now have some duplicates)\n",
      "full_data = full_data.groupby([\"date\", \"path\"]).sum().reset_index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Remove any paths that have fewer than 100 visits over the entire data set\n",
      "def add_visit_sum(group):\n",
      "    group[\"total_path_visits\"] = group.visits.sum()\n",
      "\n",
      "    return group\n",
      "\n",
      "full_data = full_data.groupby([\"path\"]).apply(add_visit_sum)\n",
      "full_data = full_data[full_data[\"total_path_visits\"] > 100]\n",
      "\n",
      "del full_data[\"total_path_visits\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# add proportion of visits each path accounted for each day\n",
      "def add_proportion(group):\n",
      "    group[\"visits_proportion\"] = group.visits.astype(float) / group.total_visits\n",
      "\n",
      "    return group\n",
      "\n",
      "full_data = full_data.groupby(\"date\").apply(add_proportion)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Save full_data to file\n",
      "full_data.to_csv(dr.data_path(\"visits-by-date-path.csv\"), encoding=\"utf-8\", index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read the data\n",
      "full_data = pd.read_csv(dr.data_path(\"visits-by-date-path.csv\"), parse_dates=[0], encoding=\"utf-8\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Work on a single series in isolation\n",
      "\n",
      "The following cells extract a single path so that it can be worked on in isolation.\n",
      "\n",
      "Set the `path` and `column` variables to whatever you're interested in.\n",
      "\n",
      "Unless otherwise stated all moving window functions are exponentially weighted with a span of 5."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Functions\n",
      "def add_averages(frame, column):\n",
      "    \"\"\"\n",
      "    Adds two weekly averages (averages for the same weekday over time).\n",
      "        week_average:         Moving average for this weekday\n",
      "        week_average_shifted: Moving average for this weekday shifted by one week (so last week's value).\n",
      "    \n",
      "    frame:  The DataFrame to work on\n",
      "    column: The column name to add the averages for\n",
      "\n",
      "    Returns `frame` with the two averages added.\n",
      "    \"\"\"\n",
      "    frame = frame.reset_index()\n",
      "    def grouper(group):\n",
      "        group[\"week_average\"] = pd.ewma(group[column], com=0.4)\n",
      "        \n",
      "        return group\n",
      "    frame = frame.groupby(\"day_of_week\").apply(grouper)\n",
      "    frame = frame.set_index(\"date\")\n",
      "    frame[\"week_average_shifted\"] = frame.shift(7).week_average\n",
      "    frame = frame.reset_index()\n",
      "    return frame\n",
      "\n",
      "def add_standard_deviations(frame, column):\n",
      "    \"\"\"\n",
      "    Adds three weekly standard devations.\n",
      "        week_std:         Moving standard deviation for this weekday\n",
      "        week_std_shifted: Moving standard deviation for this weekday shifted by one week (so last week's value)\n",
      "        max_std:          Max week_std_shifted over the previous 3 days (this allows us to stabalise quicker after an event)\n",
      "\n",
      "    frame:  The DataFrame to work on\n",
      "    column: The column name to add the standard deviations for.\n",
      "\n",
      "    Returns `frame` with the standard deviations added.\n",
      "    \"\"\"\n",
      "    frame = frame.reset_index()\n",
      "    def grouper(group):\n",
      "        group[\"week_std\"] = pd.ewmstd(group[column], com=0.4)\n",
      "        \n",
      "        return group\n",
      "    frame = frame.groupby(\"day_of_week\").apply(grouper)\n",
      "    frame = frame.set_index(\"date\")\n",
      "    frame[\"week_std_shifted\"] = frame.shift(7).week_std\n",
      "    frame[\"max_std\"] = pd.rolling_max(frame.week_std_shifted, 3)\n",
      "    frame = frame.reset_index()\n",
      "    return frame\n",
      "\n",
      "def calculate_deviation(frame, column, alpha=0.4):\n",
      "    \"\"\"\n",
      "    Calculate deviation from the mean and attempt to identify unusual records.\n",
      "        deviation:            Deviation from the average for the day of the week starting from last week.\n",
      "        calculated_deviation: A calculated deviation that takes into account the previous data point's deviation.\n",
      "                              The intention is to consider data points less unusual if the previous point was unusual.\n",
      "        z_score:              The calculated_deviation in terms of the max_std.\n",
      "        is_unusual:           A flag describing whether the data point is unusual.\n",
      "                              This actually contains the max column value so that it's easier to plot.\n",
      "    \n",
      "    frame:  The DataFrame to work on\n",
      "    column: The column name to add the deviations to.\n",
      "    \"\"\"\n",
      "    frame[\"deviation\"] = frame[column] - frame.week_average_shifted\n",
      "    frame[\"deviation_average\"] = pd.rolling_min(pd.ewma(frame.deviation, span=2), 3)\n",
      "    frame = frame.set_index(\"date\")\n",
      "    frame[\"deviation_average_shifted\"] = frame.shift(1).deviation\n",
      "    frame = frame.reset_index()\n",
      "    \n",
      "    frame[\"calculated_deviation\"] = np.abs(np.where(\n",
      "             np.abs(frame.deviation - frame.deviation_average_shifted * alpha) < np.abs(frame.deviation),\n",
      "             np.sign(frame.deviation) * (frame.deviation - frame.deviation_average_shifted * alpha),\n",
      "             frame.deviation\n",
      "             ))\n",
      "    del frame[\"deviation_average\"], frame[\"deviation_average_shifted\"]\n",
      "    frame[\"z_score\"] = frame[\"calculated_deviation\"] / frame[\"max_std\"]\n",
      "    frame[\"is_unusual\"] = np.where(\n",
      "            frame[\"z_score\"]>5,\n",
      "            frame[column].max(),\n",
      "            0-frame[column].max())\n",
      "    return frame\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Extract just trade tariff\n",
      "path = \"/trade-tariff\"\n",
      "column = \"visits\"\n",
      "\n",
      "single_path = full_data.set_index([\"path\"]).ix[path].reset_index().set_index([\"date\"])\n",
      "single_path.asfreq(\"D\")\n",
      "del single_path[\"path\"]\n",
      "single_path = single_path.reset_index()\n",
      "single_path[\"day_of_week\"] = single_path[\"date\"].apply(lambda item: item.weekday())\n",
      "\n",
      "single_path = add_averages(single_path, column)\n",
      "single_path = add_standard_deviations(single_path, column)\n",
      "single_path = calculate_deviation(single_path, column, alpha=0.65)\n",
      "\n",
      "# Plot that shizzle\n",
      "single_path.set_index(\"date\")[[column, \"deviation\", \"calculated_deviation\", \"max_std\", \"is_unusual\"]].plot(figsize=(15, 8))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "single_path.to_csv(dr.data_path(\"%s-visits.csv\" % path[1:]), encoding=\"utf-8\", index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Full data experiments\n",
      "\n",
      "The following cells are experiments on the full data set. The work done on single paths in isolation is a lot better."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add day of week\n",
      "full_data[\"day_of_week\"] = full_data[\"date\"].apply(lambda item: item.weekday())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add moving window stats by day\n",
      "#full_data = full_data.set_index([\"date\", \"path\", \"day_of_week\"])\n",
      "full_data = full_data.set_index([\"date\", \"path\", \"day_of_week\"])\n",
      "full_data[\"prop_ewma\"] = pd.ewma(full_data, span=4).visits_proportion\n",
      "full_data[\"prop_ewmstd\"] = pd.ewmstd(full_data, span=4).visits_proportion\n",
      "\n",
      "full_data = full_data.reset_index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add moving window stats\n",
      "full_data = full_data.set_index([\"date\", \"path\"])\n",
      "full_data[\"prop_ewma\"] = pd.ewma(full_data, span=28).visits_proportion\n",
      "full_data[\"prop_ewmstd\"] = pd.ewmstd(full_data, span=28).visits_proportion\n",
      "\n",
      "full_data = full_data.reset_index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add shifted moving average\n",
      "date_index = full_data.set_index([\"date\", \"path\"])\n",
      "shifted = date_index.unstack().shift(7).stack()\n",
      "date_index[\"prev_prop_ewma\"] = shifted[\"prop_ewma\"]\n",
      "date_index[\"prev_prop_ewmstd\"] = shifted[\"prop_ewmstd\"]\n",
      "full_data = date_index.reset_index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Identify outliers\n",
      "full_data[\"offset\"] = full_data[\"visits_proportion\"] - full_data[\"prev_prop_ewma\"]\n",
      "full_data[\"abs_offset\"] = np.abs(full_data[\"offset\"])\n",
      "full_data[\"outlier\"] = full_data[\"abs_offset\"] > (8 * full_data[\"prev_prop_ewmstd\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_data[full_data[\"outlier\"] & (full_data[\"date\"] > datetime(2012, 11, 1))][:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jobsearch = full_data[full_data[\"path\"] == \"/trade-tariff\"]\n",
      "jobsearch[jobsearch[\"date\"] > datetime(2012, 11, 1)].set_index(\"date\")[[\"visits\", \"abs_offset\", \"prop_ewmstd\"]].plot(subplots=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_data[(full_data[\"path\"] == \"/jobsearch\") & (full_data[\"date\"] > datetime(2012, 12, 1))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pivoted[\"day_of_week\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# add column for day of week\n",
      "full_data[\"day_of_week\"] = full_data[\"date\"].apply(lambda item: item.weekday())\n",
      "\n",
      "full_data = full_data.set_index([\"date\", \"path\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}